{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplified learning based on\n",
    "https://colab.research.google.com/drive/1WemHvycYcoNTDr33w7p2HL3FF72Nj88i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain-groq \n",
    "!pip -q install -U langchain_community tiktoken langchainhub\n",
    "!pip -q install -U langchain langgraph \n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langgraph\n",
      "Version: 0.0.48\n",
      "Summary: langgraph\n",
      "Home-page: https://www.github.com/langchain-ai/langgraph\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/dave/dev/python-agent-learn/.venv/lib/python3.9/site-packages\n",
      "Requires: langchain-core\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Any, Dict, List\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain.callbacks.base import AsyncCallbackHandler, BaseCallbackHandler\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.outputs import LLMResult\n",
    "\n",
    "\n",
    "class TokenPrintingCallback(AsyncCallbackHandler):\n",
    "    \"\"\"Async callback handler that can be used to handle callbacks from langchain.\n",
    "      Callbacks are documented here: https://python.langchain.com/v0.1/docs/modules/callbacks/async_callbacks/\n",
    "    \"\"\"\n",
    "\n",
    "    async def on_chat_model_start(self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs: Any) -> Any:\n",
    "        pass\n",
    "        # return await super().on_chat_model_start(serialized, messages, run_id=run_id, parent_run_id=parent_run_id, tags=tags, metadata=metadata, **kwargs)\n",
    "\n",
    "    async def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n",
    "        total_tokens = response.llm_output.get(\"token_usage\").get(\"total_tokens\")\n",
    "        print(f\"\\033[95mUsed total tokens: {total_tokens}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mUsed total tokens: 36\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# from typing import Any, Optional, Union  # Import Any from typing module\n",
    "# from uuid import UUID\n",
    "# from langchain_core.outputs import GenerationChunk, ChatGenerationChunk\n",
    "\n",
    "GROQ_LLM = ChatGroq(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            callbacks=[TokenPrintingCallback()]\n",
    "        )\n",
    "\n",
    "GROQ_LLM.invoke(\"hello\").content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_markdown_file(content, filename):\n",
    "  \"\"\"Writes the given content as a markdown file to the local directory.\n",
    "\n",
    "  Args:\n",
    "    content: The string content to write to the file.\n",
    "    filename: The filename to save the file as.\n",
    "  \"\"\"\n",
    "  with open(f\"{filename}.md\", \"w\") as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mUsed total tokens: 251\u001b[0m\n",
      "'customer_feedback'\n"
     ]
    }
   ],
   "source": [
    "#Categorize EMAIL\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a Email Categorizer Agent You are a master at understanding what a customer wants when they write an email and are able to categorize it in a useful way\n",
    "\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Conduct a comprehensive analysis of the email provided and categorize into one of the following categories:\n",
    "        price_equiry - used when someone is asking for information about pricing \\\n",
    "        customer_complaint - used when someone is complaining about something \\\n",
    "        product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\n",
    "        customer_feedback - used when someone is giving feedback about a product \\\n",
    "        off_topic when it doesnt relate to any other category \\\n",
    "\n",
    "\n",
    "            Output a single cetgory only from the types ('price_equiry', 'customer_complaint', 'product_enquiry', 'customer_feedback', 'off_topic') \\\n",
    "            eg:\n",
    "            'price_enquiry' \\\n",
    "\n",
    "    EMAIL CONTENT:\\n\\n {initial_email} \\n\\n\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"initial_email\"],\n",
    ")\n",
    "\n",
    "email_category_generator = prompt | GROQ_LLM  | StrOutputParser()\n",
    "\n",
    "\n",
    "EMAIL = \"\"\"HI there, \\n\n",
    "I am emailing to say that I had a wonderful stay at your resort last week. \\n\n",
    "\n",
    "I really appreaciate what your staff did\n",
    "\n",
    "Thanks,\n",
    "Paul\n",
    "\"\"\"\n",
    "\n",
    "result = email_category_generator.invoke({\"initial_email\": EMAIL})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mUsed total tokens: 425\u001b[0m\n",
      "{'email_draft': \"Dear Paul,\\n\\nThank you so much for taking the time to share your wonderful feedback about your recent stay with us! We're thrilled to hear that our staff were able to make a positive impact on your experience.\\n\\nWe truly appreciate your kind words and are grateful for customers like you who make our job so rewarding.\\n\\nThank you again for choosing to stay with us, and we hope to have the pleasure of welcoming you back soon.\\n\\nBest regards,\\nSarah, Resident Manager\"}\n"
     ]
    }
   ],
   "source": [
    "## Write Draft Email\n",
    "draft_writer_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the Email Writer Agent take the INITIAL_EMAIL below  from a human that has emailed our company email address, the email_category \\\n",
    "            that the categorizer agent gave it and the research from the research agent and \\\n",
    "            write a helpful email in a thoughtful and friendly way.\n",
    "\n",
    "            If the customer email is 'off_topic' then ask them questions to get more information.\n",
    "            If the customer email is 'customer_complaint' then try to assure we value them and that we are addressing their issues.\n",
    "            If the customer email is 'customer_feedback' then try to assure we value them and that we are addressing their issues.\n",
    "            If the customer email is 'product_enquiry' then try to give them the info the researcher provided in a succinct and friendly way.\n",
    "            If the customer email is 'price_equiry' then try to give the pricing info they requested.\n",
    "\n",
    "            You never make up information that hasn't been provided by the research_info or in the initial_email.\n",
    "            Always sign off the emails in appropriate manner and from Sarah the Resident Manager.\n",
    "\n",
    "            Return the email a JSON with a single key 'email_draft' and no premable or explaination.\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    INITIAL_EMAIL: {initial_email} \\n\n",
    "    EMAIL_CATEGORY: {email_category} \\n\n",
    "    RESEARCH_INFO: {research_info} \\n\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"initial_email\",\"email_category\",\"research_info\"],\n",
    ")\n",
    "\n",
    "draft_writer_chain = draft_writer_prompt | GROQ_LLM | JsonOutputParser()\n",
    "\n",
    "email_category = 'customer_feedback'\n",
    "research_info = None\n",
    "\n",
    "print(draft_writer_chain.invoke({\"initial_email\": EMAIL, \"email_category\":email_category,\"research_info\":research_info}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        initial_email: email\n",
    "        email_category: email category\n",
    "        draft_email: LLM generation\n",
    "        final_email: LLM generation\n",
    "        research_info: list of documents\n",
    "        info_needed: whether to add search info\n",
    "        num_steps: number of steps\n",
    "    \"\"\"\n",
    "    initial_email : str\n",
    "    email_category : str\n",
    "    draft_email : str\n",
    "    final_email : str\n",
    "    research_info : List[str]\n",
    "    info_needed : bool\n",
    "    num_steps : int\n",
    "    draft_email_feedback : dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_email(state):\n",
    "    \"\"\"take the initial email and categorize it\"\"\"\n",
    "    print(\"---CATEGORIZING INITIAL EMAIL---\")\n",
    "    initial_email = state['initial_email']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "\n",
    "    email_category = email_category_generator.invoke({\"initial_email\": initial_email})\n",
    "    print(email_category)\n",
    "    # save to local disk\n",
    "    write_markdown_file(email_category, \"email_category\")\n",
    "\n",
    "    return {\"email_category\": email_category, \"num_steps\":num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_email_writer(state):\n",
    "    print(\"---DRAFT EMAIL WRITER---\")\n",
    "    ## Get the state\n",
    "    initial_email = state[\"initial_email\"]\n",
    "    email_category = state[\"email_category\"]\n",
    "    research_info = state[\"research_info\"]\n",
    "    num_steps = state['num_steps']\n",
    "    num_steps += 1\n",
    "\n",
    "    # Generate draft email\n",
    "    draft_email = draft_writer_chain.invoke({\"initial_email\": initial_email,\n",
    "                                     \"email_category\": email_category,\n",
    "                                     \"research_info\":research_info})\n",
    "    print(draft_email)\n",
    "    # print(type(draft_email))\n",
    "\n",
    "    email_draft = draft_email['email_draft']\n",
    "    write_markdown_file(email_draft, \"draft_email\")\n",
    "\n",
    "    return {\"draft_email\": email_draft, \"num_steps\":num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_printer(state):\n",
    "    \"\"\"print the state\"\"\"\n",
    "    print(\"---STATE PRINTER---\")\n",
    "    print(f\"Initial Email: {state['initial_email']} \\n\" )\n",
    "    print(f\"Email Category: {state['email_category']} \\n\")\n",
    "    print(f\"Draft Email: {state['draft_email']} \\n\" )\n",
    "    print(f\"Final Email: {state['final_email']} \\n\" )\n",
    "    print(f\"Research Info: {state['research_info']} \\n\")\n",
    "    print(f\"Info Needed: {state['info_needed']} \\n\")\n",
    "    print(f\"Num Steps: {state['num_steps']} \\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_to_research(state):\n",
    "    \"\"\"\n",
    "    Route email to web search or not.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE TO RESEARCH---\")\n",
    "    initial_email = state[\"initial_email\"]\n",
    "    email_category = state[\"email_category\"]\n",
    "\n",
    "\n",
    "\n",
    "    return \"draft_email\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"categorize_email\", categorize_email) # categorize email\n",
    "# workflow.add_node(\"research_info_search\", research_info_search) # web search\n",
    "workflow.add_node(\"state_printer\", state_printer)\n",
    "workflow.add_node(\"draft_email_writer\", draft_email_writer)\n",
    "# workflow.add_node(\"analyze_draft_email\", analyze_draft_email)\n",
    "# workflow.add_node(\"rewrite_email\", rewrite_email)\n",
    "# workflow.add_node(\"no_rewrite\", no_rewrite)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"categorize_email\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"categorize_email\",\n",
    "    route_to_research,\n",
    "    {\n",
    "        # \"research_info\": \"research_info_search\",\n",
    "        \"draft_email\": \"draft_email_writer\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"draft_email_writer\",\"state_printer\")\n",
    "\n",
    "workflow.add_edge(\"state_printer\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL1 = \"\"\"HI there, \\n\n",
    "I am emailing to find out the current price of Bitcoin. \\n\n",
    "\n",
    "Can you please help me/\n",
    "\n",
    "Thanks,\n",
    "John\n",
    "\"\"\"\n",
    "\n",
    "EMAIL2 = \"\"\"HI there, \\n\n",
    "I am emailing to say that I had a wonderful stay at your resort last week. \\n\n",
    "\n",
    "I really appreaciate what your staff did\n",
    "\n",
    "Thanks,\n",
    "Paul\n",
    "\"\"\"\n",
    "\n",
    "EMAIL3 = \"\"\"HI there, \\n\n",
    "I am emailing to say that the resort weather was way to cloudy and overcast. \\n\n",
    "I wanted to write a song called 'Here comes the sun but it never came'\n",
    "\n",
    "What should be the weather in Arizona in April?\n",
    "\n",
    "I really hope you fix this next time.\n",
    "\n",
    "Thanks,\n",
    "George\n",
    "\"\"\"\n",
    "\n",
    "EMAIL4 = \"\"\"HI there, \\n\n",
    "Why can't I get to sing?\n",
    "\n",
    "Thanks,\n",
    "Ringo\n",
    "\"\"\"\n",
    "\n",
    "EMAIL5 = \"\"\"HI there, \\n\n",
    "Thanks for confirming my booking\n",
    "\n",
    "Thanks,\n",
    "Ringo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CATEGORIZING INITIAL EMAIL---\n",
      "\u001b[95mUsed total tokens: 242\u001b[0m\n",
      "'price_enquiry'\n",
      "---ROUTE TO RESEARCH---\n",
      "'Finished running: categorize_email:'\n",
      "---DRAFT EMAIL WRITER---\n",
      "\u001b[95mUsed total tokens: 400\u001b[0m\n",
      "{'email_draft': \"Hi John, \\n\\nThank you for reaching out to us about the current price of Bitcoin. Unfortunately, as the price of Bitcoin is constantly changing, I don't have the most up-to-date information to provide you. I recommend checking a reliable cryptocurrency website or exchange for the most current pricing information.\\n\\nIf you have any other questions or need further assistance, please don't hesitate to ask.\\n\\nBest regards,\\nSarah, Resident Manager\"}\n",
      "'Finished running: draft_email_writer:'\n",
      "---STATE PRINTER---\n",
      "Initial Email: HI there, \n",
      "\n",
      "I am emailing to find out the current price of Bitcoin. \n",
      "\n",
      "\n",
      "Can you please help me/\n",
      "\n",
      "Thanks,\n",
      "John\n",
      " \n",
      "\n",
      "Email Category: 'price_enquiry' \n",
      "\n",
      "Draft Email: Hi John, \n",
      "\n",
      "Thank you for reaching out to us about the current price of Bitcoin. Unfortunately, as the price of Bitcoin is constantly changing, I don't have the most up-to-date information to provide you. I recommend checking a reliable cryptocurrency website or exchange for the most current pricing information.\n",
      "\n",
      "If you have any other questions or need further assistance, please don't hesitate to ask.\n",
      "\n",
      "Best regards,\n",
      "Sarah, Resident Manager \n",
      "\n",
      "Final Email: None \n",
      "\n",
      "Research Info: None \n",
      "\n",
      "Info Needed: None \n",
      "\n",
      "Num Steps: 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "inputs = {\"initial_email\": EMAIL1,\"research_info\": None, \"num_steps\":0}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
